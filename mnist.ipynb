{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconhecimento de dígitos na base de dados MNIST\n",
    "\n",
    "Neste notebook é descrito uma solução para o desafio de reconhecer dígitos (0 à 9) na base de dados [MNIST](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "A base de dados MNIST consiste de imagens de dígitos 60 mil amostras no conjunto de treino e 10 mil no conjunto de teste, tamanho 28*28 pixels.\n",
    "Neste exercício, o conjunto de treino foi subdividido randomicamente entre treino e validação (80% e 20%, respectivamente), possibilitando aferir a acurácia do modelo a cada época de treino. \n",
    "É então selecionado o modelo que obteve maior acurácia no subconjunto de validação como sendo o modelo final, empregando-o no conjnunto de teste da base MNIST.\n",
    "\n",
    "Desenvolvido em Python3, foram usadas as seguintes bibliotecas:\n",
    "numpy, pytorch, torchvision, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn,optim, utils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As imagens dos conjuntos de treino e teste são baixadas e armazenadas localmente no caminho indicado, posteriormente convertidas em Tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "valid_size = 0.2\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root='.pytorch/MNIST_data/', train=True,\n",
    "                                           download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='.pytorch/MNIST_data/', train=False,\n",
    "                                          download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de treino é randomizado e dividido em dois subconjuntos: treino e validação, conforme a proporção estipulada anteriormente em $valid\\_size$ (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "print(\"Quantidade de dados no subconjuntos de: \\ntreino: %d \\nvalidação: %d\"%(len(train_idx),len(valid_idx)))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "train_loader = utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "            sampler=train_sampler)\n",
    "valid_loader = utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "            sampler=valid_sampler)\n",
    "test_loader = utils.data.DataLoader(test_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, pode-se vizualizar o conjunto de treinamento (ou validação) atual e seus respectivos labels. No código abaixo é selecionado um batch de treino, as imagens são então convertidas para o formato numpy e plotadas com auxílio da biblioteca matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleciona um batch de treino\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "#cria uma figura de tamanho 16x3 polegadas\n",
    "fig = plt.figure(figsize=(16, 3))\n",
    "#itera sob o batch selecionado, adicionando as imagens e labels na figura\n",
    "for idx in np.arange(batch_size):\n",
    "    ax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo a Rede\n",
    "Foi utilizado neste exercício uma rede perceptron com duas hidden layers, possuindo como entrada um Tensor de dimensão\n",
    "784\\*1 (que corresponde ao tamanho da imagem 28\\*28 pixels), 1024 nós em cada hidden layer e um Tensor de dimensão 10, correspondendo à probabilidade de cada uma das 10 classes existentes no conjunto de dados. \n",
    "Foram empregados os seguintes hiperparâmetros:\n",
    "- Função de ativação ReLU, \n",
    "- dropout 0.2\n",
    "- função de loss [cross entropy](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy) \n",
    "- otimização com [SGD (stochastic gradient descent)](http://ruder.io/optimizing-gradient-descent/index.html#stochasticgradientdescent) \n",
    "- learning rate em 0.01.\n",
    "- treinamento com total de 40 épocas, sendo o modelo final aquele com maior acurácia na validação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #converte a imagem de entrada p/ 784*1\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "epochs = 40\n",
    "valid_loss_min = np.Inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento da Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    #itera os batchs de treino\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "    #validacao do modelo a cada época\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    print('Epoch {} \\tTraining Loss: {:.6f} \\tValid Loss: {:.6f}'.format(epoch+1, train_loss, valid_loss))\n",
    "\n",
    "    #Se erro da validação diminuir, salva o modelo atual no arquivo\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min, valid_loss))\n",
    "        torch.save(model.state_dict(), 'model.pth')\n",
    "        valid_loss_min = valid_loss\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste \n",
    "Por fim, o modelo obtido é utilizado para predição de classes no conjunto de testes da base MNIST.\n",
    "É reportado também a acurácia para cada uma das 10 classes presentes neste conjunto, possibilitando identificar \n",
    "a proporção de acerto individualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for data, target in test_loader:\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opcionalmente, pode-se visualizar um batch de imagens de testes e as predições obtidas pelo modelo, conforme a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Seleciona um batch de teste\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# testa imagens no modelo treinado\n",
    "output = model(images)\n",
    "_, preds = torch.max(output, 1)\n",
    "images = images.numpy()\n",
    "\n",
    "#cria uma figura de tamanho 16x3 polegadas\n",
    "fig = plt.figure(figsize=(16, 3))\n",
    "#itera sob o batch selecionado adicionando as imagens, predições e respectivos labels na figura\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
